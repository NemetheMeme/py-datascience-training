correlation - linear relationship between 2 numerical values
+ positive correlation -> when one raises, the other one also raises
- negative correlation ->  when one raises, the other one goes down
no correlation -> no pattern -> for example, sock color and math grade
correlation has a value between [-1,1] ->

how to read the graph -> ascending line -> positive correlation
                      -> descending line -> negative correlation
                      -> chaotic -> no correlation


Error / Average Error
The difference between the estimated value and the real value
- visualization of residual plot type
/**
from sklearn.metrics import mean_absolute_error, mean_squared_error
# we assume we have predicted values
y_true = data["reading score"]
y_pred = 0.8 * data["math score"] + 20  # example of simple prediction

mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
print(mae, mse)
**/

Median
- middle value
- boxplot
np.median(dataFrame['numerical_values'])

Quartile
- values that  share the data in 4 egal parts
- boxplot
np.percentile(dataFrame['numerical_data'], X)
X can be:
Q1 = 25% percentile
Q2 = 50% median
Q3 = 75% percentile

Outliner
- the value that goes out of the general pattern
- boxplot, scatter plot

Distribution
- how the values are spread compared to average
- histogram, KDE

Confidence Interval
- estimation of average uncertainty
- barplot

Variance
- measures how dispersed are datas
- if the math scores have a big variance -> students have different results, if the variance is low, scores are similar
- real appliances:
    -> in education you see how uniform are the scores between students
    -> in finance you see how the prices of an action fluctuate(investment risk)

np.var(dataFrame['numerical_values'], ddof=0)
ddof = population

Standard deviation
- square root of variance
np.std(dataFrame['numerical_values'], ddof=0)

Pearson correlation
data[['first_numerical_values','second_numerical_values']].corr().iloc[0.1]

data.describe() -> for quick statistics = median, average, min, max, quartile

errors between real values and predictions - simple regresion
from sklearn.metrics import mean_absolute_error, mean_squared_error
mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)

